{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy_parking System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"paddlepadlle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install paddleocr==2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(help='==SUPPRESS==', use_gpu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, image_dir=None, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\emman/.paddleocr/2.4\\\\ocr\\\\det\\\\en\\\\en_ppocr_mobile_v2.0_det_infer', det_limit_side_len=960, det_limit_type='max', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_sast_polygon=False, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_box_type='box', det_pse_scale=1, rec_algorithm='CRNN', rec_model_dir='C:\\\\Users\\\\emman/.paddleocr/2.4\\\\ocr\\\\rec\\\\en\\\\en_number_mobile_v2.0_rec_infer', rec_image_shape='3, 32, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\emman\\\\anaconda3\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\emman/.paddleocr/2.4\\\\ocr\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_model_dir=None, table_char_type='en', table_char_dict_path=None, layout_path_model='lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config', model_name_or_path=None, max_seq_length=512, label_map_path='./vqa/labels/labels_ser.txt', mode='structure', lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv2', structure_version='STRUCTURE')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from paddleocr import PaddleOCR, draw_ocr # main OCR dependencies\n",
    "from matplotlib import pyplot as plt # plot images\n",
    "import cv2 #opencv\n",
    "import os # folder directory navigation\n",
    "import base64\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Setup model\n",
    "ocr_model = PaddleOCR(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sender(json,files):\n",
    "    \n",
    "    url = \"http://localhost:2023/api/v1/vehicles/entrance\"\n",
    "\n",
    "    payload = json\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    headers = {}\n",
    "\n",
    "    response = requests.request(\"POST\", api, headers=headers, data=payload, files=files)\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ocr function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-13 18:15:10,327] [ WARNING] paddleocr.py:358 - Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/01/13 18:15:10] root WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-13 18:15:10,381] [   DEBUG] predict_system.py:70 - dt_boxes num : 0, elapse : 0.05445981025695801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/01/13 18:15:10] root DEBUG: dt_boxes num : 0, elapse : 0.05445981025695801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-13 18:15:10,385] [   DEBUG] predict_system.py:89 - rec_res num  : 0, elapse : 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/01/13 18:15:10] root DEBUG: rec_res num  : 0, elapse : 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ocr(imgP):\n",
    "    \n",
    "    ten=''\n",
    "    result = ocr_model.ocr(img_path)\n",
    "    for res in result:\n",
    "        \n",
    "        ten=ten+res[1][0]\n",
    "#         print(ten)\n",
    "    return ten\n",
    "   \n",
    "\n",
    "img_path = os.path.join('.', 'images0.jpg')\n",
    "kenzo=ocr(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-13 18:15:19,760] [   DEBUG] connectionpool.py:228 - Starting new HTTP connection (1): localhost:2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[2023/01/13 18:15:19] urllib3.connectionpool DEBUG: Starting new HTTP connection (1): localhost:2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-13 18:15:20,006] [   DEBUG] connectionpool.py:456 - http://localhost:2023 \"POST /api/v1/vehicles/entrance HTTP/1.1\" 201 441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/01/13 18:15:20] urllib3.connectionpool DEBUG: http://localhost:2023 \"POST /api/v1/vehicles/entrance HTTP/1.1\" 201 441\n",
      "{\"status\":201,\"data\":{\"message\":\"Vehicle Exit successfuly\",\"data\":{\"id\":\"3b9f2340-935d-11ed-9d57-8d5526918e30\",\"plateText\":\"RAF123B\",\"imageUrl\":\"https://res.cloudinary.com/http-voicetoworld-netlify-app/image/upload/v1673623546/projects/smartparking/58300b0b-a94c-4cba-89c4-c9775dda189e_1673623544.107.jpg\",\"isInside\":false,\"exitedAt\":\"2023-01-13T16:15:19.953Z\",\"createdAt\":\"2023-01-13T16:13:35.991Z\",\"updatedAt\":\"2023-01-13T16:15:19.955Z\"}}}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json                    \n",
    "\n",
    "import requests\n",
    "\n",
    "api = 'http://localhost:2023/api/v1/vehicles/entrance'\n",
    "#url = \"https://0805-105-178-48-6.ngrok.io/api/v1/Vehicles/create\"\n",
    "\n",
    "payload={'plateText': 'RAF123B'}\n",
    "files=[\n",
    "  ('photo',('images1.jpg',open('images1.jpg','rb'),'image/jpeg'))\n",
    "]\n",
    "print(type(files))\n",
    "headers = {}\n",
    "\n",
    "response = requests.request(\"POST\", api, headers=headers, data=payload, files=files)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bring it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-qjdp5db9\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_412\\450397752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mimgGray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mnumberPlates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplateCascade\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgGray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnumberPlates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-qjdp5db9\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frameWidth = 640    #Frame Width\n",
    "franeHeight = 480   # Frame Height\n",
    "\n",
    "plateCascade = cv2.CascadeClassifier(cv2.data.haarcascades +\"testCar.xml\")\n",
    "minArea = 500\n",
    "\n",
    "cap =cv2.VideoCapture(1)\n",
    "cap.set(3,frameWidth)\n",
    "cap.set(4,franeHeight)\n",
    "cap.set(10,150)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    success , img  = cap.read()\n",
    "\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    numberPlates = plateCascade .detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in numberPlates:\n",
    "        area = w*h\n",
    "        if area > minArea:\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(img,\"NumberPlate\",(x,y-5),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "            imgRoi = img[y:y+h,x:x+w]\n",
    "            cv2.imshow(\"ROI\",imgRoi)\n",
    "            \n",
    "   \n",
    "    cv2.imshow(\"Result\",img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF ==ord('s'):\n",
    "        cv2.imwrite(\"./images\"+str(count)+\".jpg\",imgRoi)\n",
    "        cv2.rectangle(img,(0,200),(640,300),(0,255,0),cv2.FILLED)\n",
    "        cv2.putText(img,\"Scan Saved\",(15,265),cv2.FONT_HERSHEY_COMPLEX,2,(0,0,255),2)\n",
    "        cv2.imshow(\"Result\",img)\n",
    "        ocr(img)\n",
    "        \n",
    "        kenzo=ocr(imgRoi)   \n",
    "        son={'plateText': kenzo}\n",
    "        files=[\n",
    "         ('photo',(\"images\"+str(count)+\".jpg\",open(\"images\"+str(count)+\".jpg\",'rb'),'image/jpeg'))\n",
    "          ]\n",
    "        print(type(files))\n",
    "        payload={'plateText': kenzo}\n",
    "#         payload = json.dumps(son )\n",
    "        response = requests.request(\"POST\", api, headers=headers, data=payload, files=files)\n",
    "       \n",
    "\n",
    "#         sender(payload,files)\n",
    "        print(response.text)\n",
    "        \n",
    "        cv2.waitKey(500)\n",
    "#         count+=1\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
